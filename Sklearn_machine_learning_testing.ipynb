{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Sklearn machine learning testing",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNRIjSYTge9l3fVydwu/i5E",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KOdin2/Machine-learning/blob/Classification/Sklearn_machine_learning_testing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IrUTAi5XJpdG"
      },
      "source": [
        "This workbook allows a .csv file of data to be uploaded and then classified using different machine learning algorhtims from SKlearn. Different parameters of each type of algorthim is tested and the one which gives the best overall accuracy is choosen as the best results "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRQ7e9nG6wYq"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from sklearn.model_selection import KFold\n",
        "import pandas as pd\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import time\n",
        "import io\n",
        "import pandas as pd\n",
        "\n",
        "import progressbar\n",
        "from time import sleep"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5Nyt-xCdxS_"
      },
      "source": [
        "Import all classifiers for testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yI7fuTAD_LC2"
      },
      "source": [
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.datasets import make_blobs\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import ExtraTreesClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from collections import Counter\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import neighbors, datasets\n",
        "from sklearn import svm\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.naive_bayes import ComplementNB\n",
        "from sklearn.naive_bayes import MultinomialNB \n",
        "import math"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhtCtDNOWZVB"
      },
      "source": [
        "def summary(results):\n",
        "\n",
        "  arr = np.asarray(results)\n",
        "  summary_results = []\n",
        "  total = []\n",
        "  name_index = 0\n",
        "\n",
        "  for classifier in range(0, 11):\n",
        "\n",
        "    name = arr[0,name_index]\n",
        "\n",
        "    total_conf = np.sum(arr[:,name_index+4])\n",
        "    total_count = np.sum(arr[:,name_index+5])\n",
        "\n",
        "    total_acc = round(((total_conf[0][0]+total_conf[1][1]) / np.sum(total_conf)) * 100,2)\n",
        "\n",
        "    total_rec, total_pur = overall_rec_and_pur(total_conf)\n",
        "\n",
        "    metal_rec = round((total_conf[1][1] / np.sum(total_conf[1,:])) * 100, 2)\n",
        "    metal_pur = round((total_conf[1][1] / np.sum(total_conf[:,1])) * 100, 2)\n",
        "\n",
        "    not_metal_rec = round((total_conf[0][0] / np.sum(total_conf[0,:])) * 100,2)\n",
        "    not_metal_pur = round((total_conf[0][0] / np.sum(total_conf[:,0])) * 100,2)\n",
        "\n",
        "    summary_results.extend([name, total_acc, total_rec, total_pur, total_conf, total_count, metal_rec,metal_pur, not_metal_rec,not_metal_pur  ])\n",
        "    name_index+=7\n",
        "\n",
        "  #total.append(summary_results)\n",
        "  return summary_results"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAIqcUD0gu_8"
      },
      "source": [
        "#this function will calcualte the overall recovery and purity rate\n",
        "def overall_rec_and_pur(con):\n",
        "  a=b=rec=pur = 0\n",
        "  #loop through rows to obtain overall recovery rate\n",
        "  for row in con:\n",
        "    total_of_row = row[a]/np.sum(row)\n",
        "    if math.isnan(total_of_row):\n",
        "      total_of_row=0\n",
        "    rec = rec + total_of_row\n",
        "    a+=1\n",
        "  #loops through columns to obtain overall purity rate\n",
        "  for column in con.T:\n",
        "    total_of_column = column[b]/np.sum(column)\n",
        "    if math.isnan(total_of_column):\n",
        "      total_of_column=0\n",
        "    pur = pur + total_of_column\n",
        "    b+=1\n",
        "    \n",
        "  #return recovery rate and purity rate to 2dp\n",
        "  return round((rec/a)*100,2) , round((pur/b)*100,2)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUT-3gZWPaG0"
      },
      "source": [
        "# this function takes in the model, x and y test and returns the result\n",
        "def rates(model, x_test, y_test):\n",
        "  pred = model.predict(x_test)\n",
        "  conf = confusion_matrix(y_test, pred)\n",
        "  rec, pur = overall_rec_and_pur(conf)\n",
        "  samples = Counter(y_test)\n",
        "  #return overall recovry, purity, confusion matrix and counter of smaples\n",
        "  return rec, pur, conf, samples"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_bBJhokc4N8_"
      },
      "source": [
        "class machine_learning_algorithms:\n",
        "\n",
        "      #init runs every time we add a new acc\n",
        "      #accruacy. is a class varible\n",
        "      #self. is a instance varible\n",
        "  def __init__(self, df_tt, df_ho): #constructor in c++\n",
        "\n",
        "      self.df_tt = df_tt\n",
        "      self.df_ho = df_ho\n",
        "\n",
        "      self.x_train =self.df_tt.drop(['Label'], axis='columns')\n",
        "      self.y_train =self.df_tt.Label\n",
        "      self.x_test =self.df_ho.drop(['Label'], axis='columns')\n",
        "      self.y_test =self.df_ho.Label\n",
        "\n",
        "  def decision_tree(self):\n",
        "      #create and train a decison tree model\n",
        "      self.dt_model = DecisionTreeClassifier(random_state=0)\n",
        "      self.dt_model.fit(self.x_train, self.y_train)\n",
        "\n",
        "      self.dt_acc = round((self.dt_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "      self.dt_rec , self.dt_pur, self.dt_conf, self.dt_samples =  rates(self.dt_model, self.x_test, self.y_test)\n",
        "\n",
        "      self.dt_output = [\"Decision tree\" ,self.dt_acc, self.dt_rec, self.dt_pur , self.dt_conf, self.dt_samples, \"N/A\"]\n",
        "\n",
        "      return self.dt_output\n",
        "  \n",
        "  def random_forest(self):\n",
        "      rf_best_acc = 0\n",
        "      for number_of_trees in range(1,26):     \n",
        "     \n",
        "        self.rf_model = RandomForestClassifier(n_estimators=number_of_trees, random_state=0)\n",
        "        self.rf_model.fit(self.x_train, self.y_train)\n",
        "        self.rf_acc = round((self.rf_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "        if  self.rf_acc > rf_best_acc:\n",
        "            rf_best_acc =  self.rf_acc\n",
        "\n",
        "            self.rf_rec , self.rf_pur, self.rf_conf, self.rf_samples =  rates(self.rf_model, self.x_test, self.y_test)\n",
        "\n",
        "            self.rf_output = [\"Random forest\", self.rf_acc, self.rf_rec, self.rf_pur , self.rf_conf, self.rf_samples, number_of_trees]\n",
        "\n",
        "      return self.rf_output\n",
        "\n",
        "  def extra_trees(self):\n",
        "      et_best_acc = 0\n",
        "      for number_of_trees in range(1,26):     \n",
        "     \n",
        "        self.et_model = ExtraTreesClassifier(n_estimators=number_of_trees, random_state=0)\n",
        "        self.et_model.fit(self.x_train, self.y_train)\n",
        "        self.et_acc = round((self.et_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "        if  self.et_acc > et_best_acc:\n",
        "            et_best_acc =  self.et_acc\n",
        "\n",
        "            self.et_rec , self.et_pur, self.et_conf, self.et_samples =  rates(self.et_model, self.x_test, self.y_test)\n",
        "\n",
        "            self.et_output = [\"Extra randomised trees\" , self.et_acc, self.et_rec, self.et_pur , self.et_conf, self.et_samples, number_of_trees]\n",
        "\n",
        "      return self.et_output\n",
        "\n",
        "\n",
        "  def adaboost(self):\n",
        "      ada_best_acc = 0\n",
        "      for number_of_trees in range(10,260, 10):     \n",
        "     \n",
        "        self.ada_model = AdaBoostClassifier(n_estimators=number_of_trees, random_state=0)\n",
        "        self.ada_model.fit(self.x_train, self.y_train)\n",
        "        self.ada_acc = round((self.ada_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "        if  self.ada_acc > ada_best_acc:\n",
        "            ada_best_acc =  self.ada_acc\n",
        "\n",
        "            self.ada_rec , self.ada_pur, self.ada_conf, self.ada_samples =  rates(self.ada_model, self.x_test, self.y_test)\n",
        "\n",
        "            self.ada_output = [\"Adaboost\",self.ada_acc, self.ada_rec, self.ada_pur , self.ada_conf, self.ada_samples, number_of_trees]\n",
        "      \n",
        "      return self.ada_output\n",
        "\n",
        "\n",
        "  def svm_linear(self):\n",
        "      svm_lin_best_acc = 0\n",
        "      for number in range(1,26):     \n",
        "     \n",
        "        self.svm_lin_model = SVC(C=number, kernel='linear', random_state=0 )\n",
        "        self.svm_lin_model.fit(self.x_train, self.y_train)\n",
        "        self.svm_lin_acc = round((self.svm_lin_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "        if  self.svm_lin_acc > svm_lin_best_acc:\n",
        "            svm_lin_best_acc =  self.svm_lin_acc\n",
        "\n",
        "            self.svm_lin_rec , self.svm_lin_pur, self.svm_lin_conf, self.svm_lin_samples =  rates(self.svm_lin_model, self.x_test, self.y_test)\n",
        "\n",
        "            self.svm_lin_output = [\"SVM linear\" ,self.svm_lin_acc, self.svm_lin_rec, self.svm_lin_pur , self.svm_lin_conf, self.svm_lin_samples, number]\n",
        "\n",
        "      return self.svm_lin_output\n",
        "\n",
        "  def svm_poly(self):\n",
        "      svm_poly_best_acc = 0\n",
        "      for number in range(1,26):     \n",
        "     \n",
        "        self.svm_poly_model = SVC(C=number, kernel='poly', random_state=0 )\n",
        "        self.svm_poly_model.fit(self.x_train, self.y_train)\n",
        "        self.svm_poly_acc = round((self.svm_poly_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "        if  self.svm_poly_acc > svm_poly_best_acc:\n",
        "            svm_poly_best_acc =  self.svm_poly_acc\n",
        "\n",
        "            self.svm_poly_rec , self.svm_poly_pur, self.svm_poly_conf, self.svm_poly_samples =  rates(self.svm_poly_model, self.x_test, self.y_test)\n",
        "\n",
        "            self.svm_poly_output = [\"SVM polynomial\" ,self.svm_poly_acc, self.svm_poly_rec, self.svm_poly_pur , self.svm_poly_conf, self.svm_poly_samples, number]\n",
        "\n",
        "      return self.svm_poly_output\n",
        "\n",
        "  def svm_rbf(self):\n",
        "      svm_rbf_best_acc = 0\n",
        "      for number in range(1,26):     \n",
        "     \n",
        "        self.svm_rbf_model = SVC(C=number, kernel='rbf', random_state=0 )\n",
        "        self.svm_rbf_model.fit(self.x_train, self.y_train)\n",
        "        self.svm_rbf_acc = round((self.svm_rbf_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "        if  self.svm_rbf_acc > svm_rbf_best_acc:\n",
        "            svm_rbf_best_acc =  self.svm_rbf_acc\n",
        "\n",
        "            self.svm_rbf_rec , self.svm_rbf_pur, self.svm_rbf_conf, self.svm_rbf_samples =  rates(self.svm_rbf_model, self.x_test, self.y_test)\n",
        "\n",
        "            self.svm_rbf_output = [\"SVM rbf\" , self.svm_rbf_acc, self.svm_rbf_rec, self.svm_rbf_pur , self.svm_rbf_conf, self.svm_rbf_samples, number]\n",
        "\n",
        "      return self.svm_rbf_output\n",
        "\n",
        "\n",
        "  def nb_gaussian(self):\n",
        "      self.nb_gaus_model = GaussianNB()\n",
        "      self.nb_gaus_model.fit(self.x_train, self.y_train)\n",
        "\n",
        "      self.nb_gaus_acc = round((self.nb_gaus_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "      self.nb_gaus_rec , self.nb_gaus_pur, self.nb_gaus_conf, self.nb_gaus_samples =  rates(self.nb_gaus_model, self.x_test, self.y_test)\n",
        "\n",
        "      self.nb_gaus_output = [\"Naive Bayesian gaussian\", self.nb_gaus_acc, self.nb_gaus_rec, self.nb_gaus_pur , self.nb_gaus_conf, self.nb_gaus_samples,\"N/A\"]\n",
        "\n",
        "      return self.nb_gaus_output\n",
        "\n",
        "  def nb_complement(self):\n",
        "      self.nb_comp_model = ComplementNB()\n",
        "      self.nb_comp_model.fit(self.x_train, self.y_train)\n",
        "\n",
        "      self.nb_comp_acc = round((self.nb_comp_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "      self.nb_comp_rec , self.nb_comp_pur, self.nb_comp_conf, self.nb_comp_samples =  rates(self.nb_comp_model, self.x_test, self.y_test)\n",
        "\n",
        "      self.nb_comp_output = [\"Naive Bayesian complement\" , self.nb_comp_acc, self.nb_comp_rec, self.nb_comp_pur , self.nb_comp_conf, self.nb_comp_samples, \"N/A\"]\n",
        "\n",
        "      return self.nb_comp_output\n",
        "\n",
        "\n",
        "  def nb_multinomial(self):\n",
        "      self.nb_multi_model = MultinomialNB()\n",
        "      self.nb_multi_model.fit(self.x_train, self.y_train) \n",
        "\n",
        "      self.nb_multi_acc = round((self.nb_multi_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "      self.nb_multi_rec , self.nb_multi_pur, self.nb_multi_conf, self.nb_multi_samples =  rates(self.nb_multi_model, self.x_test, self.y_test)\n",
        "\n",
        "      self.nb_multi_output = [\"Naive Bayesian multinomial\" , self.nb_multi_acc, self.nb_multi_rec, self.nb_multi_pur , self.nb_multi_conf, self.nb_multi_samples, \"N/A\"]\n",
        "\n",
        "      return self.nb_multi_output\n",
        "\n",
        "  def k_nearest_neighbours(self):\n",
        "      knn_best_acc = 0\n",
        "      for n_neighbors in range(1,20):     \n",
        "     \n",
        "        self.knn_model =  neighbors.KNeighborsClassifier(n_neighbors)\n",
        "        self.knn_model.fit(self.x_train, self.y_train)\n",
        "        self.knn_acc = round((self.knn_model.score(self.x_test, self.y_test))*100,2)\n",
        "\n",
        "        if  self.knn_acc > knn_best_acc:\n",
        "            knn_best_acc =  self.knn_acc\n",
        "\n",
        "            self.knn_rec , self.knn_pur, self.knn_conf, self.knn_samples =  rates(self.knn_model, self.x_test, self.y_test)\n",
        "\n",
        "            self.knn_output = [\"K nearrest neighbours\" ,self.knn_acc, self.knn_rec, self.knn_pur , self.knn_conf, self.knn_samples, n_neighbors]\n",
        "      return self.knn_output\n",
        "\n",
        "  def run_ml_models(self):\n",
        "    \n",
        "      bar = progressbar.ProgressBar(maxval=11, \\\n",
        "          widgets=[progressbar.Bar('=', '[', ']'), ' ', progressbar.Percentage()])\n",
        "      bar.start()\n",
        "\n",
        "      self.all_results = []\n",
        "      \n",
        "      self.all_results.extend(self.decision_tree())\n",
        "      self.all_results.extend(self.random_forest())\n",
        "      self.all_results.extend(self.extra_trees())\n",
        "      #print(\"25% Complete\")\n",
        "      bar.update(3)\n",
        "      self.all_results.extend(self.adaboost())\n",
        "      self.all_results.extend(self.svm_linear())\n",
        "      self.all_results.extend(self.svm_poly())\n",
        "      bar.update(3)\n",
        "      #print(\"50% Complete\")\n",
        "      self.all_results.extend(self.svm_rbf())\n",
        "      self.all_results.extend(self.nb_gaussian())\n",
        "      self.all_results.extend(self.nb_complement())\n",
        "      bar.update(3)\n",
        "      #print(\"75% Complete\")\n",
        "      self.all_results.extend(self.nb_multinomial())\n",
        "      self.all_results.extend(self.k_nearest_neighbours())\n",
        "\n",
        "      bar.update(2)\n",
        "      bar.finish()\n",
        "\n",
        "      return self.all_results"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hKwxxUVjF1v5"
      },
      "source": [
        "#creates a header for the csv file for all 11 machine learning algotrhis\n",
        "Header = ['Algorithm' ,'Overall accuracy', 'Overall recovery rate', 'Overall purity rate', 'Confusion matrix', 'No. samples','Varible']\n",
        "csv_header = []\n",
        "for number in range(0,11):\n",
        "  csv_header.extend(Header)\n",
        "csv_header = []\n",
        "Summary_Header = ['Algorithm' ,'Overall accuracy', 'Overall recovery rate', 'Overall purity rate', 'Confusion matrix', 'No. samples', 'Metal Rec', 'Metal Pur', 'Not metal Rec', 'Not metal pur']"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjp-fots60Pt",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "ebfdc5a5-cd0f-48cc-9d0f-f1030a87318d"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2705fd2a-495b-4eb7-8804-b4f81e3ff720\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2705fd2a-495b-4eb7-8804-b4f81e3ff720\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving All colours - Br.csv to All colours - Br.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GIUizQBj23_F",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f567613a-5d06-47e1-b620-31f26b3fbd8a"
      },
      "source": [
        "#\n",
        "number_of_splits = 10\n",
        "kf = KFold(n_splits=number_of_splits, shuffle=True, random_state = 0)\n",
        "\n",
        "t0 = time.time()\n",
        "\n",
        "#For every loaded in .csv file \n",
        "for key in uploaded:\n",
        "\n",
        "  #display loaded in file and assign to dataframe called loaded_file\n",
        "  print(\"File uploaded: \" +str(key))\n",
        "  loaded_file = pd.read_csv(io.BytesIO(uploaded[key]))\n",
        "  loaded_file = loaded_file.abs()\n",
        "\n",
        "  #Aquire output file name for loaded in data set\n",
        "  output_file_name = input(\"Enter output file name: \")\n",
        " \n",
        "  total_results = []\n",
        "  results = []\n",
        "  data_set = 1\n",
        "\n",
        "\n",
        "  for train_index, test_index in kf.split(loaded_file):\n",
        "\n",
        "    print(\"Fold \" + str(data_set))\n",
        "    data_set+=1\n",
        "\n",
        "    #sleep to allow the status bar to work\n",
        "    sleep(0.2)\n",
        "    \n",
        "    #assign the train set and holdout set\n",
        "    training_data_set  = loaded_file.iloc[train_index]\n",
        "    test_data_set = loaded_file.iloc[test_index]\n",
        "\n",
        "    #Create instance of class which asssigns train and test data sets for class use\n",
        "    machine_learning = machine_learning_algorithms(training_data_set, test_data_set)\n",
        "    #Run run_ml_models which tests all models and obtains their resu;ts\n",
        "    results.append(machine_learning.run_ml_models())\n",
        "\n",
        "\n",
        "  with open('holdout_results_output_' +  output_file_name + '.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(csv_header)\n",
        "    writer.writerows(results)\n",
        "    \n",
        "  total_results.append(summary(results))\n",
        "  total_results = np.reshape(total_results, (11, 10))\n",
        "\n",
        "  with open('holdout_summary_' +output_file_name+ '.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(Summary_Header)\n",
        "    writer.writerows(total_results)\n",
        "\n",
        "  if output_file_name!= \"test\":\n",
        "    files.download('holdout_results_output_'+  output_file_name + '.csv') \n",
        "    files.download('holdout_summary_' + output_file_name + '.csv') \n",
        "\n",
        "#print time taken for test\n",
        "t1 = time.time()\n",
        "total = t1-t0\n",
        "print(\"Time Taken: \" + str(total))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File uploaded: All colours - Br.csv\n",
            "Enter output file name:test\n",
            "Fold 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "Fold 2\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "Fold 3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "Fold 4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "Fold 5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "Fold 6\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "Fold 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "Fold 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "Fold 9\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "Fold 10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[========================================================================] 100%\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Testing of algorithms complete!\n",
            "\n",
            "TIME TAKEN: 190.97478461265564\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}